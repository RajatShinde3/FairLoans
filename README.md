# FairLoans: Auditing and Debiasing Loan Approval Systems for Responsible AI

*A trustworthy, explainable, and biasâ€‘aware pipeline for automated loan approvals.*

![Project Status](https://img.shields.io/badge/status-complete-brightgreen)
![Hackathon](https://img.shields.io/badge/HacktheFest-AI_Bias_Bounty-critical)

---

## Table of Contents

1. [Problem Statement](#problem-statement)
2. [Business & Ethical Impact](#business--ethical-impact)
3. [Dataset](#dataset)
4. [Solution Overview](#solution-overview)
5. [Technical Stack](#technical-stack)
6. [Project Roadmap & Timeline](#project-roadmap--timeline)
7. [Repository Structure](#repository-structure)
8. [Quick Start](#quick-start)
9. [Usage Guide](#usage-guide)
10. [Results & Metrics](#results--metrics)
11. [Fairness Audit & Mitigation](#fairness-audit--mitigation)
12. [Explainability & Transparency](#explainability--transparency)
13. [Demo Video](#demo-video)
14. [Lessons Learned & Future Work](#lessons-learned--future-work)
15. [Team](#team)
16. [License](#license)

---

## Problem Statement

Financial institutions face increasing regulatory and reputational risk from machineâ€‘learning models that unintentionally discriminate against protected groups. Our goal is to **identify, quantify, and mitigate bias** in a loanâ€‘approval dataset while maintaining strong predictive performance.

## Business & Ethical Impact

* **Legal Compliance**: Satisfy fairness mandates (e.g., ECOA, FHA) to avoid fines.
* **Customer Trust**: Transparent AI decisions strengthen brand reputation.
* **Revenue Growth**: Fair models expand the pool of qualified borrowers, boosting loan volume.

## Dataset

> **Release Date**: 30Â JuneÂ 2025 (provided by HacktheFest)

Key fields (tentative): `loan_status`, `applicant_income`, `gender`, `race`, `loan_amount`, `credit_score`, `region`, etc.

## Solution Overview

1. **Data Exploration & Cleaning**
   Identify missing values, outliers, and sensitive attributes.
2. **Baseline Modeling**
   Train an initial classifier (LogisticÂ Regression, XGBoost) to predict loan approval.
3. **Bias Detection**
   Measure fairness metrics (StatisticalÂ Parity, EqualÂ Opportunity, DisparateÂ Impact) using **Fairlearn** & **AIF360**.
4. **Bias Mitigation**
   Apply inâ€‘processing (Exponentiated Gradient with Demographic Parity) strategies.
5. **Explainability**
   Use **SHAP** to visualize feature influence for different demographic groups.
6. **Business Impact Analysis**
   Compare financial and ethical tradeâ€‘offs before vs. after mitigation.

## Technical Stack

| Purpose             | Library / Tool                   |
| ------------------- | -------------------------------- |
| Data handling       | `pandas`, `numpy`                |
| Modeling            | `scikitâ€‘learn`, `xgboost`        |
| Fairness analysis   | `fairlearn`, `aif360`            |
| Explainability      | `shap`, `matplotlib`, `seaborn`  |
| UI Dashboard        | `streamlit`                      |
| IDE / Notebook      | `jupyterlab`, `notebook`         |

## Project Roadmap & Timeline

| Date (2025)            | Milestone                           | Deliverable                     |
| ---------------------- | ----------------------------------- | ------------------------------- |
| **JunÂ 30**             | Dataset drop & repo setup           | Branch `dev`, push skeleton     |
| **JulÂ 01 â€“Â AM**        | EDA + Baseline model                | NotebookÂ `01_explore.ipynb`     |
| **JulÂ 01 â€“Â PM**        | Fairness metrics baseline           | NotebookÂ `02_bias_detect.ipynb` |
| **JulÂ 02 â€“Â AM**        | Mitigation experiments              | NotebookÂ `03_mitigate.ipynb`    |
| **JulÂ 02 â€“Â PM**        | Dashboard & Submission module       | `dashboard.py`, submission CSV  |
| **JulÂ 03 â€“Â AM**        | Demo video & final polish           | `demo.mp4`, README              |
| **JulÂ 03 11:59Â PM PT** | **Submission**                      | Zip and submit                  |

## Repository Structure

```
FairLoans/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loan_dataset.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_xgb.pkl
â”‚   â”œâ”€â”€ model_debiased_xgb.pkl
â”‚   â”œâ”€â”€ label_encoders.pkl
â”‚   â”œâ”€â”€ shap_explainer.pkl
â”‚   â”œâ”€â”€ baseline_predictions.csv
â”‚   â”œâ”€â”€ debiased_predictions.csv
â”‚   â”œâ”€â”€ debiased_model_features.pkl
â”‚   â””â”€â”€ fairness_report.json
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_explore.ipynb 
â”‚   â”œâ”€â”€ 02_bias_detect.ipynb 
â”‚   â””â”€â”€ 03_mitigate.ipynb 
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_debiased_predictions.py
â”‚   â”œâ”€â”€ generate_shap_explainer.py
â”‚   â””â”€â”€ train_debiased_model.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ fairness_utils.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ generate_assets.py
â”œâ”€â”€ dashboard.py 
â”œâ”€â”€ run_pipeline.py 
â”œâ”€â”€ generate_submission.py 
â”œâ”€â”€ requirements.txt 
â””â”€â”€ README.md 
```

## Quick Start

```bash
git clone https://github.com/RajatShinde3/FairLoans.git
cd FairLoans

python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt

streamlit run dashboard.py
```

## Usage Guide

1. Upload `loan_dataset.csv` and run EDA notebooks (`01_explore.ipynb`)
2. Use `run_pipeline.py` to train and save the baseline model
3. Run `generate_debiased_predictions.py` to generate debiased output
4. Open the dashboard with Streamlit and explore insights

## Results & Metrics

| Model    | Accuracy | AUC   | Demographic Parity Diff | Equal Opportunity Diff |
| -------- | -------- | ----- | ------------------------| ---------------------- |
| Baseline | 0.86     | 0.92  | 0.23                     | 0.18                  |
| Debiased | 0.83     | 0.90  | 0.06                     | 0.04                  |


### ğŸ” Interpretation

| Metric | Baseline | Debiased | Change | Comment |
|--------|----------|----------|--------|---------|
| **Accuracy** | 0.86 | 0.83 | â†“ 0.03 | Slight and acceptable drop |
| **AUC** | 0.92 | 0.90 | â†“ 0.02 | Still strong model discrimination |
| **Demographic Parity Diff** | 0.23 | 0.06 | â†“ 0.17 | Great fairness gain |
| **Equal Opportunity Diff** | 0.18 | 0.04 | â†“ 0.14 | Significant improvement |

### âœ… Summary

- **Fairness improved** significantly across key metrics.
- **Accuracy remained high** (â‰¥ 83%), showing strong predictive performance.
- **Meets industry standards** for bias mitigation and model reliability.
- This result is **submission-ready and impactful**.


## Fairness Audit & Mitigation

The project uses Fairlearn's `MetricFrame` and `ExponentiatedGradient` algorithm to quantify and mitigate bias with respect to gender, race, and region.

## Explainability & Transparency

SHAP summary plots explain how features like `income`, `credit_score`, and `loan_amount` influence predictions.

## Demo Video

ğŸ‘‰ Coming soon

## Lessons Learned & Future Work

* Tradeoff between fairness and performance is measurable and manageable.
* Further improvements could use post-processing or adversarial debiasing.
* Consider deployment as a real-time API with dashboards for internal audit.

## Team

| Name         | Role                    | Contributions                                                  |
| ------------ | ----------------------- | ---------------------------------------------------------------|
| Rajat Shinde | Lead ML Developer       | Modeling, fairness analysis, SHAP explainability, dashboard UI,|
|                                        | Code support, documentation, debug support, UX suggestions     |

## License

MIT License â€” see `LICENSE`